{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms,datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e4f74d91c04ada8ba0941e49c29d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20623341e3eb4bdfb5439befe18c472b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32be53f8970d45df9547a3198084d8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f605366fbb1341bdae4d975136e100bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST('',train=True,download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test= datasets.MNIST('',train=False,download=True,transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torch.utils.data.DataLoader(test,batch_size=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3\n",
    "* defining a feed forward network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn   # classes \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We define a simple feedforward Nueral Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):   ### class Net inherit from nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()   # if you want to run __init__(self)\n",
    "        self.fc1 = nn.Linear(784,64)  # 784 = 28*28\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self,x):   # method that defines how data flow through over network\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "net = Net()   \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand([28,28])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.view([-1,28*28])  # -1 shows input is of any size (let say in a case \n",
    "# when we have batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1519, -2.2818, -2.2254, -2.4122, -2.3570, -2.3828, -2.3822, -2.3229,\n",
       "         -2.2906, -2.2495]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture # 4 \n",
    "* Optimize the algorithm for our task of recognizing the digits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0349, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1848, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of feature-sets and label\n",
    "        X, y= data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step() # adjust the weight \n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "  for idx, i in enumerate(torch.zeros([2,5])):\n",
    "                          print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.984\n"
     ]
    }
   ],
   "source": [
    "# how good the accuracy is \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "\n",
    "print(\"Accuracy = \",round(correct/total,3)) \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# analyze some data by comparing the input with the predicted output\n",
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(X[1].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
