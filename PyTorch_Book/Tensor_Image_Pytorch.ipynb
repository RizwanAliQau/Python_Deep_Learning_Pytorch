{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The introduction of convolutional neural networks revolutionized computer vision, and image-based systems have since acquired a new set of capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To participate in this revolution, you need\n",
    " to be able to load images from common image formats and then transform the data\n",
    " into a tensor representation that has the various parts of the image arranged in the\n",
    " way that PyTorch expects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An image is represented as a collection of scalars arranged in a regular grid, having a height and a width (in pixels). You might have a single scalar per grid point (the\n",
    " pixel), which would be represented as a grayscale image, or multiple scalars per grid\n",
    " point, which typically represent different colors or different features, such as depth\n",
    " from a depth camera. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have several ways of encoding numbers into colors. The most common is\n",
    " RGB, which defines a color with three numbers that represent the intensity of red,\n",
    " green and blue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 885, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "img_arr = imageio.imread('C:/Users/Haier/blue_tit.jpeg') \n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imageio.core.util.Array"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: \n",
    "PyTorch\n",
    " modules that deal with image data require tensors to be laid out as C x H x W (channels, height, and width, respectively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can use the transpose function to get to an appropriate layout. Given an input\n",
    " tensor W x H x C, you get to a proper layout by swapping the first and last channels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "img = torch.from_numpy(img_arr) \n",
    "out = torch.transpose(img, 0, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 885, 560])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: \n",
    "This operation doesn’t make a copy of the\n",
    " tensor data. Instead, out uses the same underlying storage as img and plays with the size\n",
    " and stride information at the tensor level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This arrangement is convenient because the\n",
    " operation is cheap, but (heads up) changing a pixel in img leads to a change in out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same strategy that you used\n",
    " for earlier data types, to create a data set of multiple images to use as an input for your\n",
    " neural networks, you store the images in a batch along the first dimension to obtain a\n",
    " N x C x H x W tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: \n",
    "As a more efficient alternative to using stack to build up the tensor, you can preallocate a tensor of appropriate size and fill it with images loaded from a directory which indicates that your batch will consist of 100 RGB images 256 pixels in height\n",
    " and 256 pixels in width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 \n",
    "batch = torch.zeros(100, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now you can load all images from an input directory and store\n",
    " them in the tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = 'C:/Users/Haier/Dataset/vasell_seg_datset/train/vessel'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "             if os.path.splitext(name) == '.jpg'] \n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(filename)   \n",
    "    batch[i] = torch.transpose(torch.from_numpy(img_arr), 0, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 256, 256])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural networks exhibit the best\n",
    " training performance when input data ranges from roughly 0 to 1 or –1 to 1 (an effect\n",
    " of how their building blocks are defined). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# floating point conversion and normalize\n",
    "batch = batch.float() \n",
    "batch /= 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is to compute mean and standard deviation of the input data and\n",
    " scale it so that the output has zero mean and unit standard deviation across each\n",
    " channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1] \n",
    "for c in range(n_channels): \n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])   \n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform several other operations on inputs, including geometric transformations such as rotation, scaling, and cropping. These operations may help with\n",
    " training or may be required to make an arbitrary input conform to the input\n",
    " requirements of a network, such as the size of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
