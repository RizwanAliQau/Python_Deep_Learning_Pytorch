{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PyTorch’s autograd:\n",
    " You computed the gradient of a composition of functions:the model and the loss—with respect to their innermost parameters—w and b—by propagating derivatives backward via the chain rule. The basic requirement is that all functions you’re dealing with are differentiable analytically. In this case, you can compute the gradient (which we called “the rate of change of the loss”) with respect to the parameters in one sweep. If you have a complicated model with millions of parameters, as long as the model is differentiable, computing the gradient of  loss with respect to parameters amounts to writing the analytical expression for the derivatives and evaluating them once. Granted, writing the analytical expression for the derivatives of a deep composition of linear and nonlinear functions isn’t easy and quick, either.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This situation is where PyTorch tensors come to the rescue, with a PyTorch component called autograd. PyTorch tensors can remember where they come from in terms\n",
    " of the operations and parent tensors that originated them, and they can provide the\n",
    " chain of derivatives of such operations with respect to their inputs automatically. You\n",
    " won’t need to derive your model by hand; given a forward expression, no matter how\n",
    " nested, PyTorch provides the gradient of that expression with respect to its input\n",
    " parameters automatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     Rewrite the thermometer calibration code, this time using \n",
    "    autograd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] \n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b): \n",
    "    return w * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):  \n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a parameters tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requires_grad=True argument to the tensor constructor, that argument\n",
    " is telling PyTorch to track the entire family tree of tensors resulting from operations on params. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In other words, any tensor that has params as an ancestor has access to the\n",
    " chain of functions that were called to get from params to that tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In case these\n",
    " functions are differentiable (and most PyTorch tensor operations are), the value of\n",
    " the derivative is automatically populated as a grad attribute of the params tensor.  In general, all PyTorch tensors have an attribute named grad, normally None:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All you have to do to populate it is start with a tensor with requires_grad set to True, call the model, compute the loss, and then call backward on the loss tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(model(t_u, *params), t_c) \n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4517.2969,   82.6000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the grad attribute of params contains the derivatives of the loss with\n",
    " respect to each element of params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You could have any number of tensors with requires_grad set to True and any\n",
    " composition of functions. In this case, PyTorch would compute derivatives of the loss\n",
    " throughout the chain of functions (the computation graph) and accumulate their values in the grad attribute of those tensors(the leaf nodes of the graph). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c): \n",
    "    for epoch in range(1, n_epochs + 1): \n",
    "        # This could be done at any point in the loop prior to\n",
    "        # calling loss.backward()\n",
    "\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        t_p = model(t_u, *params)  \n",
    "        loss = loss_fn(t_p, t_c) \n",
    "        loss.backward()\n",
    "        params = (params - learning_rate * params.grad).detach().requires_grad_()\n",
    "        if epoch % 500 == 0:   \n",
    "            # It’s somewhat cumbersome, but as you’ll see in\n",
    "            # “Optimizers a-la Carte,”it’s not an issue in practice.\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when you updated params, you also did an odd .detach().requires_grad_()_.  Detach the new params tensor from the computation graph associated\n",
    " with its update expression by calling .detatch(). This way, params effectively loses the\n",
    " memory of the operations that generated it. Then you can reenable tracking by calling .requires_grad_(), an in_place operation (see the trailing _) that reactivates autograd for the tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now you can release the memory held by old versions of\n",
    " params and need to backpropagate through only your current weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_un= t_u*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860116\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957697\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 5000, learning_rate = 1e-2, \n",
    "              params = torch.tensor([1.0, 0.0], requires_grad=True),\n",
    "              t_u = t_un,  \n",
    "              t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get the same result that you got previously. Good for you! Although you’re capable of computing derivatives by hand, you no longer need to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Optimizers a la carte :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update every parameter in your model yourself. The\n",
    " torch module has an optim submodule where you can find classes that implement different optimization algorithms. Here’s an abridged listing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'Optimizer',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'lr_scheduler']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every optimizer constructor takes a list of parameters (aka PyTorch tensors, typically\n",
    " with requires_grad set to True) as the first input. All parameters passed to the optimizer are retained inside the optimizer object so that the optimizer can update their\n",
    " values and access their grad attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Each optimizer exposes two methods: zero_grad and step. The former zeros the\n",
    " grad attribute of all the parameters passed to the optimizer upon construction. The\n",
    " latter updates the value of those parameters according to the optimization strategy\n",
    " implemented by the specific optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create params and instantiate a gradient descent optimizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params], lr=learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, SGD stands for Stochastic Gradient Descent. The optimizer itself is a vanilla gradient\n",
    " descent (as long as the momentum argument is set to 0.0, which is the default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The\n",
    " term stochastic comes from the fact that the gradient is typically obtained by averaging\n",
    " over a random subset of all input samples, called a minibatch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer itself,\n",
    " however, doesn’t know whether the loss was evaluated on all the samples (vanilla) or a\n",
    " random subset thereof (stochastic), so the algorithm is the same in the two cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.5483e-01, -8.2600e-04], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take your new optimizer for a spin:\n",
    "\n",
    "t_p = model(t_u, *params) \n",
    "loss = loss_fn(t_p, t_c) \n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note:\n",
    "The value of params was updated when step was called, and you didn’t have to touch\n",
    " it yourself! What happened was that the optimizer looked into params.grad and\n",
    " updated params by subtracting learning_rate times grad from it, exactly as in your\n",
    " former hand-rolled code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here’s the loop-ready code, with the extra zero_grad in the right spot (before the\n",
    " call to backward):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7761, 0.1064], requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "t_p = model(t_un, *params) \n",
    "loss = loss_fn(t_p, t_c)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " All you have to do is provide a list of params to it (that list can be extremely\n",
    " long, as needed for deep neural network models) and then forget about the details. Update your training loop accordingly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c): \n",
    "    for epoch in range(1, n_epochs + 1):  \n",
    "        t_p = model(t_u, *params)  \n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()     \n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860116\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957697\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "# It’s important that both params here are the same object; otherwise,\n",
    "# the optimizer won’t know what parameters the model used.\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "training_loop(n_epochs = 5000, \n",
    "              optimizer = optimizer, \n",
    "              params = params, \n",
    "              t_u = t_un,\n",
    "              t_c = t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analysis:\n",
    "Again, you get the same result as before. Great. You have further confirmation that\n",
    " you know how to descend a gradient by hand! To test more optimizers, all you have to\n",
    " do is instantiate a different optimizer, such as Adam, instead of SGD. The rest of the\n",
    " code stays as is. This stuff is pretty handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won’t go into much detail on Adam, but it suffices to say that it’s a more sophisticated optimizer in which the learning rate is set adaptively. In addition, it’s a lot less\n",
    " sensitive to the scaling of the parameters—so insensitive that you can go back to use the original (non-normalized) input t_u and even increase the learning rate to 1e-1. Adam won’t even blink:\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True) \n",
    "learning_rate = 1e-1 \n",
    "optimizer = optim.Adam([params], lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.612903\n",
      "Epoch 1000, Loss 3.086700\n",
      "Epoch 1500, Loss 2.928578\n",
      "Epoch 2000, Loss 2.927646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.5367, -17.3021], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 2000,\n",
    "              optimizer = optimizer,\n",
    "              params = params,  \n",
    "              t_u = t_u, # back to orignal input  \n",
    "              t_c = t_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analysis:\n",
    "The optimizer isn’t the only flexible part of your training loop. Turn your attention to\n",
    " the model. To train a neural network on the same data and the same loss, all you’d\n",
    " need to change is the model function. Doing this wouldn’t make sense in this case,\n",
    " because you know that converting Celsius to Fahrenheit amounts to a linear transformation. Neural networks allow you to remove your arbitrary assumptions about the\n",
    " shape of the function you should be approximating. Even so, neural networks manage\n",
    " to be trained even when the underlying processes are highly nonlinear (such in the\n",
    " case of describing an image with a sentence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We’ve touched on a lot of the essential concepts that will enable you to train complicated deep learning models while knowing what’s going on under the hood: backpropagation to estimate gradients, autograd, and optimizing weights of models by\n",
    " using gradient descent or other optimizers. We don’t have a whole lot more to cover.\n",
    " The rest is mostly filling in the blanks, however extensive they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we discuss how to split up samples, which sets up a perfect use case for learning to control autograd better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<<<<<<<<<<<<<<<<<<<<<<<<<<< End >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training, validation, and overfitting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A deep neural network can potentially approximate complicated functions, provided that the number of neurons—and, therefore, parameters—is high enough. The\n",
    " fewer the parameters, the simpler the shape of the function your network will be able\n",
    " to approximate. So here’s rule one:\n",
    " * if the training loss isn’t decreasing, chances are that the model is too simple for the data\n",
    " *  The other possibility is that your data doesn’t contain meaningful information for it to explain the output\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the nice folks at the\n",
    " shop sold you a barometer instead of a thermometer, you’d have little chance to predict temperature in Celsius from pressure alone, even if you used the latest neural network architecture from Quebec:\n",
    "  https://www.umontreal.ca/en/artificialintelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the validation set? Well, if the loss evaluated in the validation set\n",
    " doesn’t decrease along with the training set, your model is improving its fit of the samples it’s seeing during training, but it isn’t generalizing to samples outside this precise\n",
    " set. As soon as you evaluate the model at new, previously unseen points, the values of\n",
    " the loss function are poor. Here’s rule two:\n",
    " * if the training loss and the validation loss diverge, you’re overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s the cure, though? Good question. Overfitting looks like a problem of making\n",
    " sure that the behavior of the model in between data points is sensible for the process\n",
    " you’re trying approximate. First, you should make sure that you get enough data for\n",
    " the process. If you collected data from a sinusoidal process by sampling it regularly at\n",
    " a low frequency, you’d have a hard time fitting a model to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Avoid Overfitting:\n",
    "\n",
    "Assuming that you have enough data points, you should make sure that the model\n",
    " that’s capable of fitting the training data is as regular as possible between the data\n",
    " points. You have several ways to achieve this goal. One way is to add so-called penalization terms to the loss function to make it cheaper for the model to behave more\n",
    " smoothly and change more slowly (up to a point). Another way is to add noise to the\n",
    " input samples, to artificially create new data points between training data samples and\n",
    " force the model to try to fit them too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Several other ways are somewhat related to the\n",
    " preceding ones. But the best favor you can do for yourself, at least as a first move, is to\n",
    " make your model simpler. From an intuitive standpoint, a simpler model may not fit\n",
    " the training data as perfectly as a more complicated model would do, but it will likely\n",
    " behave more regularly between data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analyze:\n",
    "You’ve got some nice tradeoffs here. On one hand, you need to model to have\n",
    " enough capacity for it to fit the training set. On the other hand, you need the model\n",
    " to avoid overfitting. Therefore, the process for choosing the right size of a neural network model, in terms of parameters, is based on two steps: increase the size until it fits\n",
    " and then scale it down until it stops overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can split the\n",
    " data into a training set and a validation set by shuffling t_u and t_c in the same way\n",
    " and then splitting the resulting shuffled tensors into two parts. \n",
    " \n",
    " Shuffling the elements of a tensor amounts to finding a permutation of its indices.\n",
    " The randperm function does this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = t_u.shape[0] \n",
    "n_val = int(0.2 * n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples,n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = torch.randperm(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation\n",
    "train_indices = shuffled_indices[:-n_val] \n",
    "val_indices = shuffled_indices[-n_val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 9,  0, 10,  3,  4,  2,  7,  8,  5]), tensor([1, 6]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices, val_indices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get index tensors that you can use to build training and validation sets starting\n",
    " from the data tensors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training input and desired output \n",
    "train_t_u = t_u[train_indices] \n",
    "train_t_c = t_c[train_indices]\n",
    "#  validation input and desired output\n",
    "val_t_u = t_u[val_indices]\n",
    "val_t_c = t_c[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training and validation\n",
    "train_t_un = 0.1 * train_t_u \n",
    "val_t_un = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your training loop doesn’t change. You want to evaluate the validation loss at every\n",
    " epoch to have a chance to recognize whether you’re overfitting:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):   \n",
    "        train_t_p = model(train_t_u, *params) \n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        val_t_p = model(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        optimizer.zero_grad()  \n",
    "        train_loss.backward() \n",
    "        optimizer.step()\n",
    "        if epoch <= 3 or epoch % 500 == 0:   \n",
    "            print('Epoch {}, Training loss {}, Validation loss {}'.format(epoch, float(train_loss), float(val_loss)))\n",
    "    return params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True) \n",
    "learning_rate = 1e-2 \n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 90.34750366210938, Validation loss 35.44009780883789\n",
      "Epoch 2, Training loss 40.74310302734375, Validation loss 12.03737735748291\n",
      "Epoch 3, Training loss 34.29985046386719, Validation loss 11.497885704040527\n",
      "Epoch 500, Training loss 8.272359848022461, Validation loss 1.0062336921691895\n",
      "Epoch 1000, Training loss 3.6953022480010986, Validation loss 2.0580081939697266\n",
      "Epoch 1500, Training loss 2.8709726333618164, Validation loss 3.6276702880859375\n",
      "Epoch 2000, Training loss 2.72251296043396, Validation loss 4.496127128601074\n",
      "Epoch 2500, Training loss 2.695772886276245, Validation loss 4.9011125564575195\n",
      "Epoch 3000, Training loss 2.690957546234131, Validation loss 5.079550743103027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.5010, -18.3851], requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 3000,\n",
    "              optimizer = optimizer, \n",
    "              params = params,\n",
    "              train_t_u = train_t_un, \n",
    "              val_t_u = val_t_un,  \n",
    "              train_t_c = train_t_c,\n",
    "              val_t_c = val_t_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we’re not being entirely fair to the model. The validation set is small, so the validation loss will be meaningful only up to a point. In any case, note that the validation\n",
    " loss is higher than your training loss, although not by an order of magnitude.The fact\n",
    " that a model performs better on the training set is expected since the model parameters are being shaped by the training set. Your main goal is to also see both the training loss and the validation loss decreasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    "Although ideally, both losses would be\n",
    " roughly the same value, as long as validation loss stays reasonably close to the training\n",
    " loss, you know that your model is continuing to learn generalized things about your\n",
    " data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #####  Nits in autograd and switching it off :\n",
    " PyTorch allows you to switch off autograd when you don’t\n",
    " need it by using the torch.no_grad context manager. You won’t see any meaningful\n",
    " advantage in terms of speed or memory consumption on your small problem. But for\n",
    " larger models, the differences can add up. You can make sure that this context manager\n",
    " works by checking the value of the requires_grad attribute on the val_loss tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    for epoch in range(1, n_epochs + 1):  \n",
    "        train_t_p = model(train_t_u, *params)   \n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        with torch.no_grad(): # Context manager here.\n",
    "            val_t_p = model(val_t_u, *params)\n",
    "            val_loss = loss_fn(val_t_p, val_t_c)\n",
    "            # All requires_grad args are forced to False \n",
    "            # inside this block.\n",
    "            assert val_loss.requires_grad == False \n",
    "        optimizer.zero_grad()  \n",
    "        train_loss.backward() \n",
    "        optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the related set_grad_enabled context, you can also condition code to run with\n",
    " autograd enabled or disabled, according to a Boolean expression, typically indicating\n",
    " whether you’re running in training or inference. You could define a calc_forward function that takes data in input and runs model and loss_fn with or without autograd, according to a Boolean train_is argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_forward(t_u, t_c, is_train):\n",
    "    with torch.set_grad_enabled(is_train):   \n",
    "        t_p = model(t_u, *params)       \n",
    "        loss = loss_fn(t_p, t_c) \n",
    "        return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<---------------------- End Chapter # 4 --------------------------------->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Summary:\n",
    "\n",
    " Linear models are the simplest reasonable model to use to fit data. \n",
    "\n",
    " Convex optimization techniques can be used for linear models, but they don’t generalize to neural networks.\n",
    "\n",
    " Deep learning can be used for generic models that aren’t engineered to solve a specific task but can be adapted automatically to specialize in the problem at hand. \n",
    "\n",
    " Learning algorithms amount to optimizing parameters of models based on\n",
    " observations. Loss function is a measure of the error in carrying out a task, such as the error between predicted outputs and measured values. The goal is to get loss function as low as possible.\n",
    " \n",
    " The rate of change of the loss function with respect to model parameters can be used to update the same parameters in the direction of decreasing loss.\n",
    "\n",
    " The optim module in PyTorch provides a collection of ready-to-use optimizers for updating parameters and minimizing loss functions. \n",
    "\n",
    " Optimizers use the autograd feature of PyTorch to compute the gradient for\n",
    " each parameter, depending on how that parameter contributed to the final output. This feature allows users to rely on the dynamic computation graph during complex forward passes. \n",
    "\n",
    " Context managers such as with torch.no_grad(): can be used to control autograd behavior. \n",
    "\n",
    " Data is often split into separate sets of training samples and validation samples, allowing a model to be evaluated on data it wasn’t trained on. \n",
    "\n",
    " Overfitting a model happens when the model’s performance continues to\n",
    " improve on the training set but degrades on the validation set. This situation usually occurs when the model doesn’t generalize and instead memorizes the desired outputs for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
